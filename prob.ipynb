{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_tree.csv\n",
      "events.csv\n",
      "item_properties_part1.csv\n",
      "item_properties_part2.csv\n",
      "rating_matrix.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import scipy.sparse as sps\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import surprise as sp\n",
    "import os\n",
    "from sklearn.preprocessing import normalize\n",
    "import cmath\n",
    "from numpy.linalg import norm\n",
    "import surprise as sp\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "def read_data(filename):\n",
    "    dataset = pd.read_csv(filename)\n",
    "    return dataset\n",
    "\n",
    "#Evaluation Metrics\n",
    "\n",
    "#Precision\n",
    "def get_precision(hits,k,test):\n",
    "    precision = hits/k\n",
    "    P_c = precision[test.sort_values('visitorid').visitorid.unique()]\n",
    "    no_of_test_users = len(test.visitorid.unique())\n",
    "    avg_precision = sum(P_c)/no_of_test_users\n",
    "    print(avg_precision)\n",
    "    return avg_precision,P_c\n",
    "\n",
    "#Recall\n",
    "def get_recall(hits,test):\n",
    "    no_interactions = list(test.sort_values('visitorid').groupby('visitorid').count().event)\n",
    "    recall = hits[list(test.sort_values('visitorid').visitorid.unique())]/no_interactions\n",
    "    R_c = recall\n",
    "    no_of_test_users = len(test.visitorid.unique())\n",
    "    avg_recall = sum(R_c)/no_of_test_users\n",
    "    print(avg_recall)\n",
    "    return avg_recall, R_c\n",
    "\n",
    "#F-measure\n",
    "def get_fmeasure(P_c,R_c):\n",
    "    F = 2*P_c*R_c/(P_c+R_c)\n",
    "    nan_index = np.isnan(F)\n",
    "    F[nan_index] = 0\n",
    "    avg_F = sum(F)/len(F)\n",
    "    print(avg_F)\n",
    "    return avg_F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "category_tree = read_data(\"../input/category_tree.csv\")\n",
    "events = read_data(\"../input/events.csv\")\n",
    "item_1 = read_data(\"../input/item_properties_part1.csv\")\n",
    "item_2 = read_data(\"../input/item_properties_part2.csv\")\n",
    "\n",
    "print(\"Read all data in pandas object complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train and test constructed with sizes', 13314, 13314)\n",
      "(1406087, 466866)\n",
      "here 1\n",
      "here 2\n",
      "Sampled_train constructed, contains item purchases (5+ items per row)\n"
     ]
    }
   ],
   "source": [
    "# PRE PROCESSING\n",
    "# combine item matrix\n",
    "item_properties = pd.concat(([item_1, item_2]), ignore_index=True)\n",
    "events_full = events\n",
    "test, train = pd.DataFrame([]), pd.DataFrame([])\n",
    "n = events.shape[0]\n",
    "\n",
    "# use only transaction data for now\n",
    "events = events[events.event=='transaction']\n",
    "events = events.sort_values('timestamp')\n",
    "events = events[events.groupby('visitorid').visitorid.transform(len) > 1]\n",
    "\n",
    "users = sorted(events.visitorid.unique())\n",
    "items = sorted(item_properties.itemid.unique())\n",
    "groupby_users = events.groupby('visitorid')\n",
    "\n",
    "# Storing number of transactions for each user\n",
    "counts = events.groupby('visitorid').count()['timestamp'].tolist()\n",
    "ind = 0\n",
    "\n",
    "# Iterate over all users with sorted transaction history and put top 80% in train and the latter transactions in test\n",
    "for name, group in events.groupby('visitorid'):\n",
    "    train_size = int(math.ceil(0.7*n))\n",
    "    test_size = int(math.floor(0.3*n))\n",
    "    if test_size == 0:\n",
    "        test_size = 1\n",
    "    train = train.append(group.head(train_size))\n",
    "    test = test.append(group.tail(test_size))\n",
    "    ind +=1\n",
    "print('Train and test constructed with sizes',train.shape[0],test.shape[0])\n",
    "\n",
    "# create a user-item interaction matrix\n",
    "rows, cols = max(events.visitorid.unique()), max(item_properties.itemid.unique())\n",
    "print(rows,cols)\n",
    "ui_matrix = sps.lil_matrix((rows+2, cols+2), dtype=int) # empty matrix\n",
    "sampled_train = sps.lil_matrix((rows+2, cols+2), dtype=int) # empty matrix\n",
    "\n",
    "# Create a confidence matrix with binary values, 1 for transaction and 0 for none.\n",
    "for index, row in train.iterrows():\n",
    "    if row['event'] == 'transaction': #remove this to add views and add to cart event\n",
    "        ui_matrix[row['visitorid'],row['itemid']] = 1\n",
    "sample = []\n",
    "row_sums = ui_matrix[users,:].sum(axis=1)\n",
    "\n",
    "# Consider only those users who have 5 or more purchases.\n",
    "sample = [i for i in range(len(row_sums)) if row_sums[i] >=5]\n",
    "sampled_train = []\n",
    "for user_index in sample:\n",
    "    sampled_train.append(list(ui_matrix[users[user_index],:].A[0]))\n",
    "print('Sampled_train constructed, contains item purchases (5+ items per row)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict done\n"
     ]
    }
   ],
   "source": [
    "# Get ground truth using future transactions that exist in test\n",
    "# Storing a mapping between the total users in the sparse matrix and the selected subsample (5 transcations)\n",
    "user_dict = {}\n",
    "for i,v in enumerate(sample):\n",
    "    if users[v] not in user_dict:\n",
    "        user_dict[users[v]]=i\n",
    "print('Dict done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commence link analysis\n",
      "Begin loop\n",
      "Link Analysis Done\n"
     ]
    }
   ],
   "source": [
    "# LINK ANALYSIS\n",
    "print('Commence link analysis')\n",
    "\n",
    "gamma = 0.9\n",
    "A = sampled_train\n",
    "B = []\n",
    "lol = []\n",
    "\n",
    "\n",
    "for i,user in enumerate(sample):\n",
    "    B.append(A[i]/row_sums[user,0]**gamma)\n",
    "A = np.array(A)\n",
    "B = np.array(B)\n",
    "CR_prev=np.identity(len(sample))\n",
    "CR_0=CR_prev\n",
    "counter = 0\n",
    "print('Begin loop')\n",
    "while(True):\n",
    "    PR = np.dot(A.T,CR_prev)\n",
    "    CR_new = np.dot(B,PR)\n",
    "    r_s = CR_new.sum(axis=1)\n",
    "    new_matrix = CR_new / r_s[:, np.newaxis]   \n",
    "    CR_new = new_matrix+CR_0\n",
    "    if(np.linalg.norm(CR_new-CR_prev))<=10: #Lower the difference, more accurate results, time to run increases\n",
    "        break\n",
    "    CR_prev = CR_new\n",
    "    counter += 1 # How many iterations took place\n",
    "\n",
    "print('Link Analysis Done')\n",
    "PR=PR.T\n",
    "#Get recommendations\n",
    "rec = []\n",
    "k = 5\n",
    "#PR -> NxM (M-users, N-items) \n",
    "#Get top k items columnwise\n",
    "for arr in PR:\n",
    "    rec.append(arr.argsort()[-k:][::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for link analysis\n",
      "0.144099378882\n",
      "0.0754860656057\n",
      "0.0894631818492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:48: RuntimeWarning: invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "# Hits for link analysis\n",
    "test_users = test['visitorid']\n",
    "hits = np.zeros((max(users))+1)\n",
    "for ind,row in test.iterrows():\n",
    "    tu = row['visitorid']\n",
    "    if tu in user_dict:\n",
    "        algo_rec = rec[user_dict[tu]]\n",
    "        if row['itemid'] in algo_rec:\n",
    "            hits[tu]+=1\n",
    "print(\"Results for link analysis\")\n",
    "avg_precision,P_c = get_precision(hits,k,test)\n",
    "avg_recall, R_c = get_recall(hits,test)\n",
    "avg_F = get_fmeasure(P_c,R_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#User Based\n",
    "A = sampled_train\n",
    "WC = cosine_similarity(A)\n",
    "user_prod = WC.dot(A)\n",
    "user_rec = []\n",
    "k = 5\n",
    "#PR -> NxM (M-users, N-items) \n",
    "#Get top k items columnwise\n",
    "for arr in user_prod:\n",
    "    user_rec.append(arr.argsort()[-k:][::-1])\n",
    "\n",
    "test_users = test['visitorid']\n",
    "user_hits = np.zeros((max(users))+1)\n",
    "for ind,row in test.iterrows():\n",
    "    tu = row['visitorid']\n",
    "    if tu in user_dict:\n",
    "        algo_rec = user_rec[user_dict[tu]]\n",
    "        if row['itemid'] in algo_rec:\n",
    "            user_hits[tu]+=1\n",
    "\n",
    "avg_precision,P_c = get_precision(user_hits,k,test)\n",
    "avg_recall, R_c = get_recall(user_hits,test)\n",
    "avg_F = get_fmeasure(P_c,R_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "466868"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = sampled_train\n",
    "A =  sps.lil_matrix(np.array(A).T)\n",
    "WP = cosine_similarity(A,dense_output=False)\n",
    "WP.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Item Based\n",
    "A_org = np.array(sampled_train)\n",
    "A_T =  sps.lil_matrix((A_org).T)\n",
    "WP = cosine_similarity(A_T,dense_output=False)\n",
    "item_prod = A_org.dot(WP)\n",
    "item_rec = []\n",
    "k = 5\n",
    "#PR -> NxM (M-users, N-items) \n",
    "#Get top k items columnwise\n",
    "for arr in user_prod:\n",
    "    item_rec.append(arr.argsort()[-k:][::-1])\n",
    "\n",
    "test_users = test['visitorid']\n",
    "item_hits = np.zeros((max(users))+1)\n",
    "for ind,row in test.iterrows():\n",
    "    tu = row['visitorid']\n",
    "    if tu in user_dict:\n",
    "        algo_rec = item_rec[user_dict[tu]]\n",
    "        if row['itemid'] in algo_rec:\n",
    "            item_hits[tu]+=1\n",
    "\n",
    "avg_precision,P_c = get_precision(item_hits,k,test)\n",
    "avg_recall, R_c = get_recall(item_hits,test)\n",
    "avg_F = get_fmeasure(P_c,R_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(hits)\n",
    "\n",
    "len(events.visitorid.unique()),len(test.visitorid.unique())\n",
    "\n",
    "len(users)\n",
    "\n",
    "len(train.visitorid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check sparsity of the matrix\n",
    "sparsity = 100*(1 - float( len(C) )/(len(events.visitorid.unique())*len(item_properties.itemid.unique())))\n",
    "sparsity\n",
    "#len(R)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
