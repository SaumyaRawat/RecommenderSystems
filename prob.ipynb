{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_tree.csv\n",
      "events.csv\n",
      "item_properties_part1.csv\n",
      "item_properties_part2.csv\n",
      "rating_matrix.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import scipy.sparse as sps\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import surprise as sp\n",
    "import os\n",
    "from sklearn.preprocessing import normalize\n",
    "import cmath\n",
    "from numpy.linalg import norm\n",
    "import surprise as sp\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "def read_data(filename):\n",
    "    dataset = pd.read_csv(filename)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read all data in pandas object complete\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "category_tree = read_data(\"../input/category_tree.csv\")\n",
    "events = read_data(\"../input/events.csv\")\n",
    "item_1 = read_data(\"../input/item_properties_part1.csv\")\n",
    "item_2 = read_data(\"../input/item_properties_part2.csv\")\n",
    "\n",
    "print(\"Read all data in pandas object complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train and test constructed with sizes', 13314, 13314)\n",
      "(1406087, 466866)\n",
      "here 1\n",
      "here 2\n",
      "Sampled_train constructed, contains item purchases (5+ items per row)\n"
     ]
    }
   ],
   "source": [
    "# PRE PROCESSING\n",
    "# combine item matrix\n",
    "import math\n",
    "item_properties = pd.concat(([item_1, item_2]), ignore_index=True)\n",
    "events_full = events\n",
    "test, train = pd.DataFrame([]), pd.DataFrame([])\n",
    "n = events.shape[0]\n",
    "\n",
    "# use only transaction data for now\n",
    "events = events[events.event=='transaction']\n",
    "events = events.sort_values('timestamp')\n",
    "events = events[events.groupby('visitorid').visitorid.transform(len) > 1]\n",
    "\n",
    "#events = events.head(1000)\n",
    "users = sorted(events.visitorid.unique())\n",
    "items = sorted(item_properties.itemid.unique())\n",
    "groupby_users = events.groupby('visitorid')\n",
    "\n",
    "counts = events.groupby('visitorid').count()['timestamp'].tolist()\n",
    "ind = 0\n",
    "\n",
    "for name, group in events.groupby('visitorid'):\n",
    "    train_size = int(math.ceil(0.7*n))\n",
    "    test_size = int(math.floor(0.3*n))\n",
    "    if test_size == 0:\n",
    "        test_size = 1\n",
    "    train = train.append(group.head(train_size))\n",
    "    test = test.append(group.tail(test_size))\n",
    "    ind +=1\n",
    "print('Train and test constructed with sizes',train.shape[0],test.shape[0])\n",
    "# create a user-item interaction matrix\n",
    "rows, cols = max(events.visitorid.unique()), max(item_properties.itemid.unique())\n",
    "print(rows,cols)\n",
    "ui_matrix = sps.lil_matrix((rows+2, cols+2), dtype=int) # empty matrix\n",
    "sampled_train = sps.lil_matrix((rows+2, cols+2), dtype=int) # empty matrix\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    if row['event'] == 'transaction':\n",
    "        ui_matrix[row['visitorid'],row['itemid']] = 1\n",
    "print('here 1')\n",
    "sample = []\n",
    "row_sums = ui_matrix[users,:].sum(axis=1)\n",
    "#col_sums = ui_matrix[:,items].sum(axis=0)\n",
    "sample = [i for i in range(len(row_sums)) if row_sums[i] >=5]\n",
    "#sample_items = [i for i in range(len(col_sums)) if col_sums[i] >=1]\n",
    "print('here 2')\n",
    "sampled_train = []\n",
    "for user_index in sample:\n",
    "    sampled_train.append(list(ui_matrix[users[user_index],:].A[0]))\n",
    "print('Sampled_train constructed, contains item purchases (5+ items per row)')\n",
    "\n",
    "#ui_matrix = normalize(ui_matrix, norm='l1', axis=1, copy=False)\n",
    "#ui_matrix *= 5\n",
    "\n",
    "#A = pd.DataFrame(columns=['userID', 'itemID', 'rating'])\n",
    "#R,C = sampled_train.nonzero()\n",
    "#contents = sampled_train[R,C].toarray()\n",
    "#A['userID'] = pd.Series(R)\n",
    "#A['itemID'] = pd.Series(C)\n",
    "#A['rating'] = pd.Series(contents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2576, 2576)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(events.visitorid.unique()),len(test.visitorid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11719"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commence link analysis\n",
      "Begin loop\n",
      "Link Analysis Done\n"
     ]
    }
   ],
   "source": [
    "# LINK ANALYSIS\n",
    "print('Commence link analysis')\n",
    "\n",
    "gamma = 0.9\n",
    "A = sampled_train\n",
    "B = []\n",
    "lol = []\n",
    "\n",
    "\n",
    "for i,user in enumerate(sample):\n",
    "    B.append(A[i]/row_sums[user,0]**gamma)\n",
    "A = np.array(A)\n",
    "B = np.array(B)\n",
    "CR_prev=np.identity(len(sample))\n",
    "CR_0=CR_prev\n",
    "counter = 0\n",
    "print('Begin loop')\n",
    "while(True):\n",
    "    PR = np.dot(A.T,CR_prev)\n",
    "    CR_new = np.dot(B,PR)\n",
    "    r_s = CR_new.sum(axis=1)\n",
    "    new_matrix = CR_new / r_s[:, np.newaxis]   \n",
    "    CR_new = new_matrix+CR_0\n",
    "    if(np.linalg.norm(CR_new-CR_prev))<=10:\n",
    "        break\n",
    "    CR_prev = CR_new\n",
    "    counter += 1\n",
    "\n",
    "print('Link Analysis Done')\n",
    "PR=PR.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get recommendations\n",
    "rec = []\n",
    "k = 5\n",
    "#PR -> NxM (M-users, N-items) \n",
    "#Get top k items columnwise\n",
    "for arr in PR:\n",
    "    rec.append(arr.argsort()[-k:][::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict done\n"
     ]
    }
   ],
   "source": [
    "# Get ground truth using future transactions that exist in test\n",
    "user_dict = {}\n",
    "for i,v in enumerate(sample):\n",
    "    if users[v] not in user_dict:\n",
    "        user_dict[users[v]]=i\n",
    "print('Dict done')\n",
    "test_users = test['visitorid']\n",
    "hits = np.zeros((max(users))+1)\n",
    "for ind,row in test.iterrows():\n",
    "    tu = row['visitorid']\n",
    "    if tu in user_dict:\n",
    "        algo_rec = rec[user_dict[tu]]\n",
    "        if row['itemid'] in algo_rec:\n",
    "            hits[tu]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#User Based\n",
    "WC = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1406087"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.144099378882\n",
      "0.0754860656057\n",
      "0.0894631818492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "#Evaluation Metrics\n",
    "\n",
    "#Precision\n",
    "precision = hits/k\n",
    "P_c = precision[test.sort_values('visitorid').visitorid.unique()]\n",
    "no_of_test_users = len(test.visitorid.unique())\n",
    "avg_precision = sum(P_c)/no_of_test_users\n",
    "print(avg_precision)\n",
    "\n",
    "#Recall\n",
    "no_interactions = list(test.sort_values('visitorid').groupby('visitorid').count().event)\n",
    "recall = hits[list(test.sort_values('visitorid').visitorid.unique())]/no_interactions\n",
    "R_c = recall\n",
    "avg_recall = sum(R_c)/no_of_test_users\n",
    "print(avg_recall)\n",
    "\n",
    "#F-measure\n",
    "F = 2*P_c*R_c/(P_c+R_c)\n",
    "nan_index = np.isnan(F)\n",
    "F[nan_index] = 0\n",
    "avg_F = sum(F)/len(F)\n",
    "print(avg_F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2576"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.visitorid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1407398"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a802a95501d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Check sparsity of the matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msparsity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisitorid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_properties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msparsity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#len(R)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'C' is not defined"
     ]
    }
   ],
   "source": [
    "#Check sparsity of the matrix\n",
    "sparsity = 100*(1 - float( len(C) )/(len(events.visitorid.unique())*len(item_properties.itemid.unique())))\n",
    "sparsity\n",
    "#len(R)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
