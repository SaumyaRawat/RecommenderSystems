{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_tree.csv\n",
      "events.csv\n",
      "item_properties_part1.csv\n",
      "item_properties_part2.csv\n",
      "rating_matrix.csv\n",
      "rating_matrix.data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import scipy.sparse as sps\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import surprise as sp\n",
    "import os\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "def read_data(filename):\n",
    "    dataset = pd.read_csv(filename)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "category_tree = read_data(\"../input/category_tree.csv\")\n",
    "events = read_data(\"../input/events.csv\")\n",
    "item_1 = read_data(\"../input/item_properties_part1.csv\")\n",
    "item_2 = read_data(\"../input/item_properties_part2.csv\")\n",
    "\n",
    "print(\"Read all data in pandas object complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1407579, 466867)\n",
      "2756101\n"
     ]
    }
   ],
   "source": [
    "# combine item matrix\n",
    "item_properties = pd.concat(([item_1, item_2]), ignore_index=True)\n",
    "\n",
    "events_full = events\n",
    "#events = events.head(1000)\n",
    "\n",
    "# create a user-item matrix\n",
    "items = sorted(events.itemid.unique())\n",
    "rows, cols = max(events.visitorid.unique()), max(events.itemid.unique())\n",
    "print(rows,cols)\n",
    "ui_matrix = sps.lil_matrix((rows+1, cols+1)) # empty matrix\n",
    "print(len(events))\n",
    "\n",
    "for index, row in events.iterrows():\n",
    "    if row['event'] == 'view':\n",
    "        ui_matrix[int(row['visitorid']), int(row['itemid'])] += 1\n",
    "    elif row['event'] == 'addtocart':\n",
    "        ui_matrix[int(row['visitorid']), int(row['itemid'])] += 2\n",
    "    elif row['event'] == 'transaction':\n",
    "        ui_matrix[int(row['visitorid']), int(row['itemid'])] += 5\n",
    "\n",
    "index = 0        \n",
    "ui_df = pd.DataFrame(columns=['userID', 'itemID', 'rating'])\n",
    "R,C = ui_matrix.nonzero()\n",
    "contents = ui_matrix[R,C].toarray()\n",
    "ui_df['userID'] = pd.Series(R)\n",
    "ui_df['itemID'] = pd.Series(C)\n",
    "ui_df['rating'] = pd.Series(contents[0])\n",
    "\n",
    "# View all values saved in pandas object\n",
    "#print(ui_df)\n",
    "\n",
    "# Save the ratings matrix created to a human-readable csv format\n",
    "ui_df.to_csv('../input/rating_matrix.data', index=False, sep=',', header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2145179"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ui_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"d = dict.fromkeys(events.visitorid.unique(), {})\\ndf_views = events.loc[events['event'] == 'view']\\ndf_atc = events.loc[events['event'] == 'addtocart']\\ndf_tr = events.loc[events['event'] == 'transaction']\\n\\n\\nfor i,row in df_views.iterrows():\\n    if row['itemid'] in d[row['visitorid']]:\\n        d[row['visitorid']][row['itemid']] += 1\\n    else:\\n        d[row['visitorid']][row['itemid']] = 1\\n\\nfor i,row in df_atc.iterrows():\\n    if row['itemid'] in d[row['visitorid']]:\\n        d[row['visitorid']][row['itemid']] += 2\\n    else:\\n        d[row['visitorid']][row['itemid']] = 2\\n\\nfor i,row in df_tr.iterrows():\\n    if row['itemid'] in d[row['visitorid']]:\\n        d[row['visitorid']][row['itemid']] += 5\\n    else:\\n        d[row['visitorid']][row['itemid']] = 5\\n        \\nlist_of_lists = []\\nfor visitor in sorted(d.keys()):\\n    row = []\\n    for item in items:\\n        try:\\n            row.append(d[visitor][item])\\n        except KeyError:\\n            row.append(0)\\n    list_of_lists.append(row)\\n\\nui_matrix = np.array(list_of_lists)\\nprint(ui_matrix)\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''d = dict.fromkeys(events.visitorid.unique(), {})\n",
    "df_views = events.loc[events['event'] == 'view']\n",
    "df_atc = events.loc[events['event'] == 'addtocart']\n",
    "df_tr = events.loc[events['event'] == 'transaction']\n",
    "\n",
    "\n",
    "for i,row in df_views.iterrows():\n",
    "    if row['itemid'] in d[row['visitorid']]:\n",
    "        d[row['visitorid']][row['itemid']] += 1\n",
    "    else:\n",
    "        d[row['visitorid']][row['itemid']] = 1\n",
    "\n",
    "for i,row in df_atc.iterrows():\n",
    "    if row['itemid'] in d[row['visitorid']]:\n",
    "        d[row['visitorid']][row['itemid']] += 2\n",
    "    else:\n",
    "        d[row['visitorid']][row['itemid']] = 2\n",
    "\n",
    "for i,row in df_tr.iterrows():\n",
    "    if row['itemid'] in d[row['visitorid']]:\n",
    "        d[row['visitorid']][row['itemid']] += 5\n",
    "    else:\n",
    "        d[row['visitorid']][row['itemid']] = 5\n",
    "        \n",
    "list_of_lists = []\n",
    "for visitor in sorted(d.keys()):\n",
    "    row = []\n",
    "    for item in items:\n",
    "        try:\n",
    "            row.append(d[visitor][item])\n",
    "        except KeyError:\n",
    "            row.append(0)\n",
    "    list_of_lists.append(row)\n",
    "\n",
    "ui_matrix = np.array(list_of_lists)\n",
    "print(ui_matrix)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy algo\n",
    "algo1 = sp.NormalPredictor()\n",
    "algo2 = sp.KNNBasic()\n",
    "algo3 = sp.SVD()\n",
    "algo4 = sp.SVDpp()\n",
    "algo5 = sp.NMF()\n",
    "algo6 = sp.SlopeOne()\n",
    "\n",
    "file_path = os.path.abspath('../input/rating_matrix.data')\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "#data = sp.Dataset.load_from_df(ui_df[['userID', 'itemID', 'rating']], reader)\n",
    "reader = sp.Reader(line_format='user item rating', sep=',')\n",
    "data = sp.Dataset.load_from_file(file_path,reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.split(2)  # data can now be used normally\n",
    "\n",
    "for trainset, testset in data.folds():\n",
    "    algo1.train(trainset)\n",
    "    #algo2.train(trainset)\n",
    "    algo3.train(trainset)\n",
    "    #algo4.train(trainset)\n",
    "    #algo5.train(trainset)\n",
    "    #algo6.train(trainset)\n",
    "    \n",
    "res1 = sp.evaluate(algo1, data, measures=['RMSE', 'MAE'])\n",
    "#res2 = sp.evaluate(algo2, data, measures=['RMSE', 'MAE'])\n",
    "res3 = sp.evaluate(algo3, data, measures=['RMSE', 'MAE'])\n",
    "#res4 = evaluate(algo4, data, measures=['RMSE', 'MAE'])\n",
    "#res5 = evaluate(algo5, data, measures=['RMSE', 'MAE'])\n",
    "#res6 = evaluate(algo6, data, measures=['RMSE', 'MAE'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
